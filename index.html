
<!DOCTYPE html>
<html>
  <!-- <meta http-equiv="refresh" content="1;url=http://svl.stanford.edu/"> -->
<head>
  <title>Stanford Computer Vision Lab</title>
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,500,400' rel='stylesheet' type='text/css'>
  
  <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
  <!-- 
  <link href="css/font-awesome/css/bootstrap-combined.no-icons.min.css" rel="stylesheet">
  <link href="css/font-awesome/css/font-awesome.css" rel="stylesheet">  
  -->
  <link href="css/style.css" rel="stylesheet">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46895817-1', 'stanford.edu');
  ga('send', 'pageview');

</script>
</head>

<body>

  <!-- <p>
    <a href="http://svl.stanford.edu/"><img id="banner" src="vision_lab_banner.jpg" alt="SVL"/></a>
    <br><br><br>
  </p> -->

  <!-- header -->
  <header class="container-fluid">
    <div class="container" id="headerdiv">
      <nav id="navigation">
        <ul class="nav">
          <li class="active"><a href="index.html">Home</a></li>
          <li><a href="people.html">People</a></li>
          <li><a href="publications.html">Publications</a></li>
          <li><a href="teaching.html">Teaching</a></li>
        </ul>
      </nav>
    </div>
  </header>

  <div class="container">
  <h4>Description</h4>

  <img src="http://vision.stanford.edu/group3.jpg" id="group_picture" />
  <p>
  Research in our lab focuses on two intimately connected branches of vision research: computer vision and human vision. In both fields, we are intrigued by visual functionalities that give rise to semantically meaningful interpretations of the visual world. 
  </p>
  <p>
  In <b>computer vision</b>, we aspire to develop intelligent algorithms that perform important visual perception tasks such as object recognition, scene categorization, integrative scene understanding, human motion recognition, material recognition, etc. 
  </p>
  <p>
  In <b>human vision</b>, our curiosity leads us to study the underlying neural mechanisms that enable the human visual system to perform high level visual tasks with amazing speed and efficiency.
  </p>
  </div>

  <div class="container">
    <h4>Highlights</h4>
    <div style="text-align: center">
    <div class="highlight">
      <div class="hcell">
      <a href="http://www.image-net.org/challenges/LSVRC/">
      <div class="himg"><img src="http://vision.stanford.edu/imagenet_proj.png.jpg" /></div>
      <div class="hdesc">ImageNet Challenge</div>
      </a>
      </div>
    </div>

    <div class="highlight">
      <div class="hcell">
      <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/">
      <div class="himg"><img src="http://vision.stanford.edu/imagenet_proj.png.jpg" /></div>
      <div class="hdesc">Automated Image Captioning</div>
      </a>
      </div>
    </div>

    <div class="highlight">
      <div class="hcell">
      <a href="https://aicare.stanford.edu">
      <div class="himg"><img src="http://vision.stanford.edu/imagenet_proj.png.jpg" /></div>
      <div class="hdesc">AI-Assisted Care</div>
      </a>
      </div>
    </div    
    <div class="highlight">
      <div class="hcell">
      <a href="http://ai.stanford.edu/sailors/">
      <div class="himg"><img src="http://vision.stanford.edu/imagenet_proj.png.jpg" /></div>
      <div class="hdesc">SAILORS program</div>
      </a>
      </div>
    </div>


    </div>
  </div>

  <div class="container">
  <div class="row">
  <div class="span6">
  <h4>News and Events</h4>
  
  <div class="newsitem">
    <div class="newsdate">January 2017</div>
    <div class="newstext">Fei-Fei is working as Chief Scientist of AI/ML of Google Cloud while being on leave from Stanford till the second half of 2018. She will continue to work with her graduate students, postdoc and collaborators at Stanford during this time.</div>
  </div>
  
  <div class="newsitem">
    <div class="newsdate">February 2016</div>
    <div class="newstext"><a href="http://vision.stanford.edu/pac/openings.html">Postdoctoral openings</a> for AI (computer vision and machine learning) and Healthcare.</div>
  </div>
  
  <div class="newsitem">
    <div class="newsdate">March 2015</div>
    <div class="newstext">Fei-Fei gave a <a href="http://www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures">TED talk</a> (+ <a href="https://www.youtube.com/watch?v=40riCqvRoMs">YouTube</a> link).</div>
  </div>

  <div class="newsitem">
    <div class="newsdate">September 2014</div>
    <div class="newstext">Jia Deng <a href="http://eccv2014.org/awards/">won</a> the best paper award at ECCV 2014, and Kevin Tang won the Outstanding Reviewer Award. Congratulations!</div>
  </div>

  <div class="newsitem">
    <div class="newsdate">August 2014</div>
    <div class="newstext">The results of ILSVRC 2014 have now <a href="http://www.image-net.org/challenges/LSVRC/2014/">been posted</a>. We saw a record number of participants (up 50% from last year), and large improvements over previous state of the art. <br> We also published an <a href="http://arxiv.org/abs/1409.0575">arXiv preprint</a> documenting the ILSVRC challenge.
    </div>
  </div>

   <div class="newsitem">
   <div class="newsdate">May 2014</div>
    <div class="newstext">We are running the <a href="http://www.image-net.org/challenges/LSVRC/2014">ImageNet Large Scale Visual Recognition Challenge 2014</a>. This year we doubled the number of images fully annotated with 200 object categories from 60K to 120K. We are welcoming a broad range of entries, including submissions from teams which may not wish to reveal the details of their methods and from teams which use extra data for training their models.
    </div>
  </div>

  <div class="newsitem">
    <div class="newsdate">December 2013</div>
    <div class="newstext">The <a href="http://www.image-net.org/challenges/LSVRC/2013/iccv2013">ImageNet Large Scale Visual Recognition Challenge 2013 workshop</a> at ICCV 2013 was a success! Slides are now available.
    </div>
  </div>

  <div class="newsitem">
    <div class="newsdate">November 2013</div>
    <div class="newstext">The results of the latest ImageNet Large Scale Visual Recognition Challenge (ILSVRC2013) are up! See them <a href="http://www.image-net.org/challenges/LSVRC/2013/results.php">here</a>.</div>
  </div>

  <div class="newsitem">
    <div class="newsdate">March 2013</div>
    <div class="newstext">We are preparing to run the <a href="http://www.image-net.org/challenges/LSVRC/2013/index">ImageNet Large Scale Visual Recognition Challenge 2013</a>. This year we will be introducing an additional object detection task with 200 object categories modeled after the PASCAL VOC detection challenge.</div>
  </div>

  <div class="newsitem">
    <div class="newsdate">March 2013</div>
    <div class="newstext">Check out the new <a href="https://sites.google.com/site/fgcomp2013/">Fine-Grained Classification Challenge</a> that will target fine-grained classification in a range of domains.</div>
  </div>

  <div class="newsitem">
    <div class="newsdate">December 2012</div>
    <div class="newstext">
      We are organizing a NIPS 2012 workshop: <a href="https://sites.google.com/site/bigvision2012/">Big Data Meets Computer Vision: First International Workshop on Large Scale Visual Recognition and Retrieval</a> (BigVision 2012).
    </div>
  </div>

  <div class="newsitem">
    <div class="newsdate">September 2012</div>
    <div class="newstext">
      We are organizing the <a href="http://vision.stanford.edu/bavm2012/">Bay Area Vision Meeting (BAVM) 2012</a>.
    </div>
  </div>

  <div class="newsitem">
    <div class="newsdate">July 2012</div>
    <div class="newstext">
      We are organizing the <a href="http://www.image-net.org/challenges/LSVRC/2012/">ImageNet Large Scale Visual Recognition Challenge</a> (ILSVRC) 2012 . In addition to classification and detection of 1,000 object categories, we introduce a third task on fine grained categorization of 120 dog subcategories. <br />
      (Results are now available <a href="http://www.image-net.org/challenges/LSVRC/2012/results.html">here</a>)
    </div>
  </div>
  </div>
  <div class="span6">
  <h4>Press Coverage</h4>
  <br />

  <blockquote>
    <p><a href="http://www.wired.com/2015/04/fei-fei-li-want-machines-think-need-teach-see/">Fei-Fei Li: If we want our machines to think, we need to teach them to see.</a></p>
    <small><cite title="Source Title">WIRED, 2015</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://blog.ted.com/building-an-ai-with-the-intelligence-of-a-toddler-fei-fei-li-at-ted2015/">Building an AI with the intelligence of a toddler: Fei-Fei Li at TED2015</a></p>
    <small><cite title="Source Title">TED Blog, 2015</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="Science-2015-Turing.pdf">Beyond the Turing Test</a></p>
    <small><cite title="Source Title">Science Magazine, 2015</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://www.nytimes.com/2014/11/18/science/researchers-announce-breakthrough-in-content-recognition-software.html?ref=science">Researchers Announce Advance in Image-Recognition Software</a></p>
    <small><cite title="Source Title">The New York Times, November 2014</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://bits.blogs.nytimes.com/2014/08/18/computer-eyesight-gets-a-lot-more-accurate/">Computer Eyesight Gets a Lot More Accurate</a></p>
    <small><cite title="Source Title">The New York Times, August 2014</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://www.nytimes.com/2012/11/20/science/for-web-images-creating-new-technology-to-seek-and-find.html?smid=go-share">Seeking a Better Way to Find Web Images</a></p>
    <small><cite title="Source Title">The New York Times, November 2012</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://news.stanford.edu/news/2011/may/brain-scan-vision-051811.html">Mind Reading</a></p>
    <small><cite title="Source Title">Stanford University News, May 2011</cite></small>
  </blockquote>

  <blockquote>
    <p><a href="http://mags.acm.org/communications/201105?pg=16#pg14">Sorting Through Photos</a></p>
    <small><cite title="Source Title">ACM Communications, May 2011</cite></small>
  </blockquote>

  </div>
  </div>
  </div>

  <!--
  <div class="container-fluid container-img">
    
    <div id="myCarousel" class="carousel slide">
    <ol class="carousel-indicators">
      <li data-target="#myCarousel" data-slide-to="0" class="active"></li>
      <li data-target="#myCarousel" data-slide-to="1"></li>
      <li data-target="#myCarousel" data-slide-to="2"></li>
    </ol>
    <div class="carousel-inner">
      <div class="active item">
        <img src="image1.png" height="100%">
        <div class="carousel-caption">
          <h5>ImageNet</h5>
          <p>ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Check it out at image-net.org</p>
        </div>
      </div>
      <div class="item">
        <img src="image2.png" height="100%">
        <div class="carousel-caption">
          <h5>Social Role Discovery in Human Events</h5>
          <p></p>
        </div>
      </div>
      <div class="item">
        <img src="image3.png" height="100%">
        <div class="carousel-caption">
          <h5>Discriminative Segment Annotation in Weakly Labeled Video</h5>
          <p></p>
        </div>
      </div>
    </div>
    <a class="carousel-control left" href="#myCarousel" data-slide="prev">&lsaquo;</a>
    <a class="carousel-control right" href="#myCarousel" data-slide="next">&rsaquo;</a>
  </div>
  </div>
  -->

  <footer>
  </footer>

  <script src="js/jquery-1.8.3.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
</body>
</html>
